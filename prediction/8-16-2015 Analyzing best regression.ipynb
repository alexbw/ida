{
 "metadata": {
  "name": "",
  "signature": "sha256:d724094f059ac43d3b6dc007f474974d868510cb0f6224b84421f96b53bf9487"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# NOTE:\n",
      "Remove HDW outlier\n",
      "Remove RBC outlier\n",
      "Update Age once > 200 iters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from scipy import ndimage\n",
      "from sklearn import cross_validation\n",
      "from sklearn import decomposition as decomp\n",
      "from sklearn.svm import SVR\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from scipy.stats import pearsonr\n",
      "np.set_printoptions(suppress=True, precision=3)\n",
      "from blurd.util import *\n",
      "from scipy import stats\n",
      "import seaborn as sns\n",
      "sns.set(style=\"ticks\")\n",
      "%pylab inline\n",
      "\n",
      "def SlidingKFold(n,fold_size):\n",
      "    full_train = set(range(n))\n",
      "    for i in range(n-fold_size):\n",
      "        valid = np.arange(i,i+fold_size)\n",
      "        train = np.array(list(full_train.difference(valid)))\n",
      "        yield train,valid"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING: pylab import has clobbered these variables: ['test']\n",
        "`%matplotlib` prevents importing * from pylab and numpy\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def regress(job, sdf, param_to_predict, train_patients, train_patient_idx, validation_patient_idx):\n",
      "    \"\"\"\n",
      "    job is the whetlab params\n",
      "    sdf is the DataFrame\n",
      "    param_to_predict is the continuous parameter we want to predict\n",
      "    train_patients are the patient names that we're training on (includes validation in folds)\n",
      "    train_idx is what we're training on\n",
      "    validate_idx is what we're testing on\n",
      "    \"\"\"\n",
      "    \n",
      "    # Prepare the blood parameter index\n",
      "    all_data = np.vstack(sdf.data.values)\n",
      "    blood_param = sdf[param_to_predict].values.astype('float')\n",
      "    blood_param_idx = ((sdf.run_time == 2*int(job['centrifugation_time'])) & (sdf.ida == \"IDA%d\" % job['nphase'])).values\n",
      "\n",
      "    # Apply a soft window to the data (better than cropping)\n",
      "    window = stats.norm.pdf(np.arange(all_data.shape[1]), loc=job['softwindow_mean'], scale=job['softwindow_variance'])\n",
      "    window /= window.max()\n",
      "    cropped_data = all_data*window[None,:]\n",
      "\n",
      "    # NOTE: Doing the unsupervised step on all the training data.\n",
      "    # Other options include:\n",
      "    # - all data (it's unsupervised so should be fine)\n",
      "    # - all training data, irrespective of blood parameters (e.g. include all centrifugation times together)\n",
      "    unsupervised_train_idx = np.array([p in train_patients for p in sdf.patient])\n",
      "    all_train_data = cropped_data[unsupervised_train_idx & blood_param_idx].copy()\n",
      "    reduc_method = ['raw','pca','nmf','kernelpca'][job['reduc_method']]\n",
      "    if reduc_method == \"raw\":\n",
      "        processed_data = ndimage.zoom(cropped_data,(1,job['n_dimensions']/cropped_data.shape[1]))\n",
      "    elif reduc_method == \"nmf\":\n",
      "        preprocessor = decomp.NMF(job['n_dimensions']).fit(all_train_data)\n",
      "        processed_data = preprocessor.transform(cropped_data)\n",
      "    elif reduc_method == \"pca\":\n",
      "        preprocessor = decomp.PCA(job['n_dimensions']).fit(all_train_data)\n",
      "        processed_data = preprocessor.transform(cropped_data)\n",
      "    elif reduc_method == \"kernelpca\":\n",
      "        preprocessor = decomp.KernelPCA(job['n_dimensions'],'rbf',gamma=1.0).fit(all_train_data)\n",
      "        processed_data = preprocessor.transform(cropped_data)\n",
      "\n",
      "    # Prepare the indices for this fold (only using the training patients)\n",
      "    train_idx = blood_param_idx & np.array([p in train_patients[train_patient_idx] for p in sdf.patient])\n",
      "    validation_idx = blood_param_idx & np.array([p in train_patients[validation_patient_idx] for p in sdf.patient])\n",
      "        \n",
      "    # Get the data and labels\n",
      "    train_data = processed_data[train_idx]\n",
      "    validation_data = processed_data[validation_idx]\n",
      "    train_y = blood_param[train_idx]\n",
      "    validation_y = blood_param[validation_idx]\n",
      "\n",
      "    assert len(train_data) == len(train_y), \"Unequal data and label sizes\"\n",
      "    assert len(validation_data) == len(validation_y), \"Unequal data and label sizes\"\n",
      "\n",
      "\n",
      "    # Train a model\n",
      "    learner = SVR('rbf', C=job['C'], gamma=job['gamma'], epsilon=job['epsilon']).fit(train_data, train_y)\n",
      "#     learner = LinearRegression(fit_intercept=True).fit(train_data, train_y)\n",
      "    pred_y = learner.predict(validation_data).ravel()\n",
      "\n",
      "    return validation_y, pred_y, np.argwhere(train_idx)[()], np.argwhere(validation_idx)[()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#####################################\n",
      "# What experiment are we looking at?\n",
      "#####################################\n",
      "\n",
      "filename = \"/Users/Alex/Dropbox/Science/Side Projects/Blood Testing/data.pandas\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Load the data and calculate strata\n",
      "\n",
      "sdf = pd.read_pickle(filename)\n",
      "\n",
      "# Create a unique tag for each patient\n",
      "sdf['patient'] = sdf.sample+\"-\"+sdf.date\n",
      "\n",
      "# Select only good vials\n",
      "sdf = sdf[sdf.good == True]\n",
      "\n",
      "# Fill in the micro/hypo calls based on these criteria (AND THEN MOVE TO THE EXTRACTION NOTEBOOK)\n",
      "# ALL THESE INDICES ARE TO CALL THE MICRO/HYPOCHROMIC ANEMIC POPULATION\n",
      "hypo_idx = sdf['%Hypo'] >= 3.9\n",
      "anemic_woman_idx = (sdf['Age'] > 15) & (sdf['Sex'] == \"F\") & (sdf.HGB < 12.0) & hypo_idx\n",
      "anemic_man_idx = (sdf['Age'] > 15) & (sdf['Sex'] == \"M\") & (sdf.HGB < 13.0) & hypo_idx\n",
      "anemic_infant_idx = (sdf['Age'] < 5) & (sdf.HGB < 11.0) & hypo_idx\n",
      "anemic_child_idx = (sdf['Age'] >= 5) & (sdf['Age'] < 15) & (sdf.HGB < 11.5) & hypo_idx\n",
      "anemic_population_idx = anemic_woman_idx | anemic_man_idx | anemic_infant_idx | anemic_child_idx\n",
      "sdf.blood_type.values[np.argwhere(anemic_population_idx)[()]] = 'anemic'\n",
      "sdf.blood_type.values[np.argwhere(anemic_population_idx == False)[()]] = 'normal'\n",
      "\n",
      "# Gather the blood-type for prediction\n",
      "int_y = sdf['blood_type'].values.copy()\n",
      "int_y[int_y == 'anemic'] = 1\n",
      "int_y[int_y == 'normal'] = 0\n",
      "int_y = int_y.astype('int32')\n",
      "sdf['int_blood_type'] = int_y\n",
      "\n",
      "# Get the patients\n",
      "patients = sdf.patient.unique()\n",
      "\n",
      "# For each patient, get the blood-type\n",
      "patient_blood_type = []\n",
      "for patient in patients:\n",
      "    this_patient = sdf[sdf.patient == patient]\n",
      "    patient_blood_type.append(sdf[sdf.patient == patient].blood_type.values[0])\n",
      "patient_blood_type = np.array(patient_blood_type)\n",
      "\n",
      "# Eliminate the duplicates\n",
      "sdf.drop_duplicates([\"patient\",\"ida\",\"run_time\"], inplace=True, take_last=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "params_to_predict = [\n",
      "# '%Hyper', \n",
      "'%Hypo', \n",
      "# '%Macro', \n",
      "# '%Micro', \n",
      "# '%Micro/%Hypo Ratio', \n",
      "# 'Age', \n",
      "# 'CH', \n",
      "# 'CHCM', \n",
      "# 'HCT', \n",
      "# 'HDW', \n",
      "# 'HGB', \n",
      "# 'MCH', \n",
      "'MCHC', \n",
      "# 'MPV', \n",
      "# 'PLT', \n",
      "# 'RBC', \n",
      "# 'RDW', \n",
      "# 'MCV',\n",
      "# 'WCB'\n",
      "]\n",
      "# # params_to_predict = ['%Hypo']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "job = {u'C': 100.0,\n",
      " u'centrifugation_time': 2,\n",
      " u'n_dimensions': 85,\n",
      " u'nphase': 3,\n",
      " u'gamma': 0.1,\n",
      " u'epsilon': 0.1,\n",
      " u'reduc_method': 3,\n",
      " u'softwindow_mean': 45,\n",
      " u'softwindow_variance': 150}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 45
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "job = {u'C': 62.0,\n",
      " u'centrifugation_time': 1,\n",
      " u'n_dimensions': 150,\n",
      " u'nphase': 3,\n",
      " u'gamma': 0.01,\n",
      " u'reduc_method': 3,\n",
      " u'epsilon': 0.19,\n",
      " u'softwindow_mean': 0,\n",
      " u'softwindow_variance': 999.7}"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prepare the data ahead of time\n",
      "all_data = np.vstack(sdf.data.values)\n",
      "window = stats.norm.pdf(np.arange(all_data.shape[1]), loc=job['softwindow_mean'], scale=job['softwindow_variance'])\n",
      "window /= window.max()\n",
      "cropped_data = all_data*window[None,:]\n",
      "preprocessor = decomp.KernelPCA(job['n_dimensions'], kernel='rbf', gamma=1).fit(cropped_data)\n",
      "sdf['processed_data'] = [d for d in preprocessor.transform(cropped_data)]\n",
      "\n",
      "nruntimes = len(np.unique(sdf.run_time))\n",
      "augmented_data = np.zeros((len(all_data),nruntimes*all_data.shape[1]))\n",
      "for patient in patients:\n",
      "    for ida in [\"IDA2\",\"IDA3\"]:\n",
      "        idx = np.argwhere((sdf.patient==patient) & (sdf.ida == ida)).ravel()\n",
      "        augmented_data[idx] = all_data[idx].ravel()\n",
      "aug_preprocessor = decomp.KernelPCA(job['n_dimensions'], kernel='rbf', gamma=1).fit(augmented_data)\n",
      "# aug_preprocessor = decomp.PCA(100).fit(augmented_data)\n",
      "sdf['augmented_data'] = [d for d in aug_preprocessor.transform(augmented_data)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# name = 'Predicting %s (patient-based folds)' % (\"%Hypo\")\n",
      "# scientist = whetlab.Experiment(name=name, access_token=None, \n",
      "#                                outcome=dict(name=\"R2\"))\n",
      "# job = scientist.best()\n",
      "job = {u'C': 100.0,\n",
      " u'centrifugation_time': 2,\n",
      " u'epsilon': 0.01,\n",
      " u'n_dimensions': 85,\n",
      " u'nphase': 3,\n",
      " u'reduc_method': 1,\n",
      " u'gamma': 0.29957913242589296,\n",
      " u'epsilon': 0.01,\n",
      " u'softwindow_mean': 97.98168763864747,\n",
      " u'softwindow_variance': 137.88216201401923}"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_patients = len(patients)\n",
      "\n",
      "all_pred_y = {}\n",
      "all_true_y = {}\n",
      "all_validation_idx = {}\n",
      "for param_to_predict in params_to_predict:\n",
      "    print(\"Working on %s\" % param_to_predict)\n",
      "\n",
      "    #####################################\n",
      "    # Get experiment\n",
      "    #####################################\n",
      "\n",
      "\n",
      "    #####################################\n",
      "    # Recreate the best experiment\n",
      "    #####################################\n",
      "\n",
      "    all_pred_y[param_to_predict] = []\n",
      "    all_true_y[param_to_predict] = []\n",
      "    all_validation_idx[param_to_predict] = []\n",
      "#     for train, validate_and_test in cross_validation.LeavePOut(n_patients, 2):\n",
      "#    for train,validate_and_test in cross_validation.KFold(n_patients,n_patients/2.0):\n",
      "    for train,validate_and_test in SlidingKFold(n_patients,2):\n",
      "        # Train a model\n",
      "        validate = validate_and_test[0:1]\n",
      "        test = validate_and_test[1:2]\n",
      "        true_y, pred_y, train_idx, validation_idx = regress(job, sdf, param_to_predict, patients, train, validate)\n",
      "        \n",
      "        all_pred_y[param_to_predict].append(pred_y)\n",
      "        all_true_y[param_to_predict].append(true_y)\n",
      "        all_validation_idx[param_to_predict].append(validation_idx.ravel())\n",
      "\n",
      "    \n",
      "    all_pred_y[param_to_predict] = np.hstack(all_pred_y[param_to_predict])\n",
      "    all_true_y[param_to_predict] = np.hstack(all_true_y[param_to_predict])\n",
      "    all_validation_idx[param_to_predict] = np.hstack(all_validation_idx[param_to_predict])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Working on %Hypo\n",
        "Working on MCHC"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now that we've cached all of the results\n",
      "# We need to calculate the \n",
      "for param_to_predict in params_to_predict:\n",
      "\n",
      "    pearson_r = pearsonr(all_true_y[param_to_predict], all_pred_y[param_to_predict])[0]\n",
      "    \n",
      "    diffs = all_pred_y[param_to_predict] - all_true_y[param_to_predict]\n",
      "    rediffs = all_true_y[param_to_predict] - np.mean(all_true_y[param_to_predict])\n",
      "    print(\"\\n\"+param_to_predict)\n",
      "    print(\"=\"*50)\n",
      "    print \"Pearson R: %2.2f\" % pearson_r\n",
      "    print \"Error: %2.2f (%2.2f,%2.2f)\" % tuple(np.percentile(diffs, [50,2.5,97.5]))\n",
      "\n",
      "    figure(figsize=(8,8))\n",
      "    g = plot(all_pred_y[param_to_predict],all_true_y[param_to_predict], 'o');\n",
      "    xlim(ylim())\n",
      "    x = xlim(); y = ylim()\n",
      "    plot([x[0],x[1]],[y[0],y[1]], '-', linewidth=2)\n",
      "\n",
      "    x = xlim()[0] + np.diff(xlim())*0.05\n",
      "    y = ylim()[1] - np.diff(ylim())*0.1\n",
      "\n",
      "    text(x,y,param_to_predict, fontsize=18)\n",
      "    xlabel(\"Predicted Value\")\n",
      "    ylabel(\"True Value\")\n",
      "    sns.despine(offset=10)\n",
      "    savefig(\"/Users/Alex/Desktop/blurd/%s-prediction.pdf\" % param_to_predict.replace(\"/\",\"-\"))\n",
      "    clf()\n",
      "\n",
      "    figure(figsize=(8,4))\n",
      "    meandiff = diffs.mean()\n",
      "    stddiff = diffs.std()\n",
      "    plot((all_pred_y[param_to_predict]+all_true_y[param_to_predict])/2.0, diffs, 'o')\n",
      "    hlines(meandiff, xlim()[0], xlim()[1])\n",
      "    hlines(meandiff+stddiff*1.96, xlim()[0], xlim()[1], color='r', linestyle='--')\n",
      "    hlines(meandiff-stddiff*1.96, xlim()[0], xlim()[1], color='r', linestyle='--')\n",
      "    lim = np.max(np.abs(np.percentile(diffs,[.1,99.9])))\n",
      "    ylim(-lim,lim)\n",
      "\n",
      "    xlabel(\"Average of predicted and true %s\" % param_to_predict)\n",
      "    ylabel(\"Difference of predicted and true %s\" % param_to_predict)\n",
      "    savefig(\"/Users/Alex/Desktop/blurd/%s-bland-altman.pdf\" % param_to_predict.replace(\"/\",\"-\"))\n",
      "    clf()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "%Hypo\n",
        "==================================================\n",
        "Pearson R: 0.91\n",
        "Error: 0.08 (-11.90,11.19)\n",
        "\n",
        "MCHC"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "==================================================\n",
        "Pearson R: 0.65\n",
        "Error: -0.03 (-1.98,2.56)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x11cbcf3d0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x11acb2bd0>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x11a829b10>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x11b076390>"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'hi'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "hi\n"
       ]
      }
     ],
     "prompt_number": 49
    }
   ],
   "metadata": {}
  }
 ]
}