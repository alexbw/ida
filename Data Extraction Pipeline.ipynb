{
 "metadata": {
  "name": "",
  "signature": "sha256:bd1ce1a77b2a06bdeefb60c5840b646af8cbc1c9f55b39fb08a8e1befba2bb50"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "import os\n",
      "import xlrd\n",
      "from glob import glob\n",
      "import skimage.io\n",
      "from joblib import Parallel, delayed\n",
      "import util\n",
      "reload(util)\n",
      "import pandas as pd\n",
      "from collections import OrderedDict\n",
      "import scipy.ndimage as ndimage"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load in all of the file paths\n",
      "base_dir = \"/Users/Alex/Dropbox/Science/side projects/Blood Testing/data\"\n",
      "experiment_folders = [f for f in glob(os.path.join(base_dir, \"*Blood*\")) if os.path.isdir(f)]\n",
      "excel_files = [glob(os.path.join(this_folder, \"*.xlsx\"))[0] for this_folder in experiment_folders]\n",
      "tiff_files = [glob(os.path.join(this_folder, \"*.tiff\")) for this_folder in experiment_folders]\n",
      "\n",
      "# Replicate the excel files so that they match up with each tiff file\n",
      "for i in range(len(excel_files)):\n",
      "    excel_files[i] = [excel_files[i]]*len(tiff_files[i])\n",
      "\n",
      "# Flatten both file lists\n",
      "excel_files = [item for sublist in excel_files for item in sublist]\n",
      "tiff_files = [item for sublist in tiff_files for item in sublist]\n",
      "IDs = [os.path.split(tiff_file)[-1].split(\".tiff\")[0] for tiff_file in tiff_files]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# THIS IS WHERE THE MEAT IS\n",
      "\n",
      "def process(img,downsample_fact=0.05):\n",
      "    import scipy.ndimage as ndimage\n",
      "    import skimage.io\n",
      "    from util import local_maxima, find_highs\n",
      "\n",
      "    # Downsample the image\n",
      "    r = []\n",
      "    for i in range(3):\n",
      "        r.append(ndimage.zoom(img[:,:,i], downsample_fact))\n",
      "    r = np.dstack(r)\n",
      "    rs = r.mean(2)\n",
      "\n",
      "    # Extract light/dark boundaries\n",
      "    h = ndimage.median_filter(np.max(rs,axis=1), (rs.shape[1]/10.0,))\n",
      "    w = ndimage.median_filter(np.max(rs,axis=0), (rs.shape[0]/50.0,))\n",
      "\n",
      "    # Find the index of the boundaries\n",
      "    height_ticks = find_highs(h,min_length=100)\n",
      "    width_ticks = find_highs(w,min_length=10)\n",
      "\n",
      "    # Extract the sub-images\n",
      "    test_imgs_bw = []\n",
      "    test_imgs = []\n",
      "    position = []\n",
      "    for iheight,height_tick in enumerate(height_ticks):\n",
      "        h1,h2 = height_tick\n",
      "        for iwidth,width_tick in enumerate(width_ticks):\n",
      "            w1,w2 = width_tick\n",
      "            Ibw = rs[h1:h2,w1:w2]\n",
      "            test_imgs_bw.append(Ibw)\n",
      "            I = r[h1:h2,w1:w2,:]\n",
      "            test_imgs.append(I)\n",
      "            position.append((iheight,iwidth))\n",
      "            \n",
      "    # Save a copy of the extracted images\n",
      "    out_imgs = test_imgs[:]\n",
      "            \n",
      "    # Shift the sub-images to remove the plug. \n",
      "    shifts = []\n",
      "    for test_img, pos in zip(test_imgs, position):\n",
      "        plug_data = np.mean(test_img[:,:,0] - test_img.mean(2), axis=1)\n",
      "        plug_data = plug_data[2:] - plug_data[:-2] # lagged derivative, smooths things out a little\n",
      "        locs = np.argwhere(local_maxima(plug_data[:20])).ravel() # only look at the beginning of the tube for the plug\n",
      "        highs = [h+1 for h in locs[np.argsort(plug_data[locs])[::-1]]]\n",
      "        if len(highs) == 0:\n",
      "            print \"NO PLUG FOUND FOR POSITION %s\" % str(pos)\n",
      "        shifts.append(highs[0])\n",
      "    test_imgs = [I[shift:,:,:] for I,shift in zip(test_imgs, shifts)]\n",
      "    \n",
      "    # Extract fittable data\n",
      "    data = [-np.median(test_img,axis=1).mean(1) for test_img in test_imgs]\n",
      "\n",
      "    return data, position, out_imgs, shifts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def do_process(tiff_file):\n",
      "    img = skimage.io.imread(tiff_file, plugin=\"freeimage\")\n",
      "    data, position, data_imgs, shifts = process(img)\n",
      "    return data, position, data_imgs, shifts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Process"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out = Parallel(n_jobs=2)(delayed(do_process)\n",
      "                          (tiff_file) for tiff_file in tiff_files)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "datas, positions, data_imgs, all_shifts = zip(*out)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Assemble a queryable dataset\n",
      "results = [dict(data=data,position=position,imgs=imgs,excel_file=excel_file,tiff_file=tiff_file,name=name, shifts=shifts) \\\n",
      " for data,position,imgs,excel_file,tiff_file,name,shifts in \n",
      " zip(datas,positions,data_imgs,excel_files,tiff_files,IDs,all_shifts)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.DataFrame(results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_metadata(excel_file):\n",
      "    workbook = xlrd.open_workbook(excel_file)\n",
      "    s = workbook.sheet_by_index(0)\n",
      "    header = [h.value for h in s.row(2)]\n",
      "    rows = [s.row(i) for i in range(4,s.nrows)]\n",
      "\n",
      "    metadata = {}\n",
      "    for i,key in enumerate(header):\n",
      "        if i == 0: \n",
      "            continue # skipping the sample label\n",
      "\n",
      "        if i == 1:\n",
      "            key = \"blood_type\"\n",
      "\n",
      "        metadata[key] = OrderedDict([(str(h[0].value), h[i].value) for h in rows])\n",
      "    \n",
      "    return metadata\n",
      "metadata = [get_metadata(excel_file) for excel_file in excel_files]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Time to clean up\n",
      "for val in list(np.unique([ib for sublist in [b['blood_type'].values() for b in metadata] for ib in sublist])):\n",
      "    print val"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Clean up the blood types\n",
      "lookup = {\"IDA\":\"ida\",\n",
      "          'ida':'ida',\n",
      "         \"MACRO\":\"macro\",\n",
      "         \"Macro\":\"macro\",\n",
      "         'macro':'macro',\n",
      "         'No Samp':\"nosample\",\n",
      "         'No sample':\"nosample\",\n",
      "         'nosample':'nosample',\n",
      "         'NO SAMPLE':'nosample',\n",
      "         \"Normal\":'normal',\n",
      "         'normal':'normal',\n",
      "         \"Spherocytosis\":'spherocytosis',\n",
      "         \"spherocytosis\":'spherocytosis',\n",
      "         u'\\u03b2-TT':'tt',\n",
      "         '\u03b2-TT':'tt',\n",
      "         'TT':'tt',\n",
      "         'tt':'tt', \n",
      "         '':''}\n",
      "\n",
      "for i in range(len(metadata)):\n",
      "    for j,(key,value) in enumerate(metadata[i]['blood_type'].items()):\n",
      "        metadata[i]['blood_type'][key] = lookup[value]\n",
      "\n",
      "headers = np.unique([ib for sublist in [m.keys() for m in metadata] for ib in sublist])\n",
      "# for header in headers:\n",
      "#     df[header] = [m[header] for m in metadata]\n",
      "# df['blood_type'] = blood_types"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the run time\n",
      "run_time = [int(n.split(\"min\")[0].split(\"_\")[-1]) for n in df.name]\n",
      "df['run_time'] = run_time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse_split_name(split_n, index, offset=0):\n",
      "    samples = []\n",
      "    ida_tag = split_n[0]\n",
      "    sample_ids = split_n[1]\n",
      "    for i,letter in enumerate(sample_ids):\n",
      "        this_sample = {\"ida\":ida_tag,\n",
      "                       \"sample\": letter.upper(),\n",
      "                       \"good\":letter.upper() != letter,\n",
      "                       \"experiment_index\":index,\n",
      "                       \"sample_index\":i+offset}\n",
      "        samples.append(this_sample)\n",
      "    return samples"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "samples = []\n",
      "# Map each sample to a letter ID\n",
      "for i,n in enumerate(df.name):\n",
      "    split_n = n.split(\"_\")\n",
      "    \n",
      "    # Some top-level filtering\n",
      "    if 'redo' in split_n:\n",
      "        split_n = n.replace(\"_redo\", \"\").split(\"_\")\n",
      "    elif 'TestSet' in split_n:\n",
      "        continue\n",
      "        \n",
      "    # Now start to identify individual samples\n",
      "    if len(split_n) == 3: # if there's an IDA tag, the sample idents, and the timing\n",
      "        samples.extend(parse_split_name(split_n[:2], i))\n",
      "    if len(split_n) == 5:\n",
      "        first_set = parse_split_name(split_n[:2], i, 0)\n",
      "        samples.extend(first_set)\n",
      "        second_set = parse_split_name(split_n[2:4], i, len(first_set))\n",
      "        samples.extend(second_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now port over everything from the df array to build one big-ass sample list\n",
      "for isample,sample in enumerate(samples):\n",
      "    idf = df.loc[sample['experiment_index']]\n",
      "    for header in headers:\n",
      "        sample[header] = metadata[sample['experiment_index']][header][sample['sample']]\n",
      "    sample['excel_file'] = idf.excel_file\n",
      "    sample['tiff_file'] = idf.tiff_file\n",
      "    sample['tiff_file_position'] = idf.position[sample['sample_index']]\n",
      "    sample['data'] = idf['data'][sample['sample_index']]\n",
      "    sample['image'] = idf.imgs[sample['sample_index']]\n",
      "    sample['run_time'] = idf.run_time\n",
      "    sample['shift'] = idf.shifts[sample['sample_index']]\n",
      "d = [s['data'] for s in samples]\n",
      "i = [s['image'] for s in samples]\n",
      "sdf = pd.DataFrame(samples)\n",
      "sdf['data'] = d # because of reasons\n",
      "sdf['image'] = i # accessible as e.g. sdf.image.values[100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert the age units into years, uniformly\n",
      "for i in range(len(sdf)):\n",
      "    if sdf['Age Units'][i].upper() == \"M\":\n",
      "        sdf['Age'][i] /= 12.0\n",
      "    elif sdf['Age Units'][i].upper() == \"D\":\n",
      "        sdf['Age'][i] /= 365.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make sure that the sex is all caps\n",
      "sdf['Sex'] = [s.upper() for s in sdf['Sex']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for header in headers:\n",
      "    try:\n",
      "        sdf[header][sdf[header] == ''] = np.nan\n",
      "        print \"Successfully compared\"\n",
      "    except:\n",
      "        print \"Not a string-valued parameter, continuing...\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# A little cleanup\n",
      "# imagesum = np.array([i.mean() for i in sdf.image.values])\n",
      "imagesum = np.array([(i[:,:,0]-i.mean(2)).mean() for i in sdf.image.values])\n",
      "sumidx = np.argsort(imagesum)\n",
      "plot(imagesum[sumidx])\n",
      "xlim(0,300)\n",
      "ylim(0,4)\n",
      "threshold = 1.2\n",
      "hlines(threshold, 0, 300)\n",
      "title(\"Mean luminosity cutoff for inclusion\")\n",
      "sdf['good'] = sdf.good.values & (imagesum > threshold)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Use this code to inspect why I chose the particular cutoff\n",
      "# 57 is blank, 58 is not\n",
      "i = 51 # now try 52\n",
      "figure(figsize=(1,4))\n",
      "imshow(sdf.image.values[sumidx[i]])\n",
      "print imagesum[sumidx[i]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Do some final cropping\n",
      "min_width = np.min([i.shape[1] for i in sdf.image.values])\n",
      "min_length = np.min([i.shape[0] for i in sdf.image.values])\n",
      "sdf['image'] = [i[:min_length,:min_width] for i in sdf.image.values]\n",
      "min_length = np.min([len(d) for d in sdf.data.values])\n",
      "sdf['data'] = [d[:min_length] for d in sdf.data.values]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 195
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sdf['blood_type'] = sdf.blood_type.fillna(\"\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from util import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = np.array([extract_redness(i).mean(1) for i in sdf.image.values])\n",
      "orig_data = data.copy()\n",
      "min_length = np.min([len(d) for d in orig_data])\n",
      "orig_data = np.array([d[:min_length] for d in orig_data])\n",
      "plug_pos = np.array([detect_plug(d) for d in orig_data])\n",
      "bad_idx = (plug_pos == -1) | (plug_pos > 40)\n",
      "\n",
      "plug_pos[bad_idx] = 0\n",
      "data = np.array([d[s:] for d,s in zip(orig_data, plug_pos)])\n",
      "\n",
      "min_length = np.min([len(d) for d in data])\n",
      "data = np.array([d[:min_length] for d in data])\n",
      "\n",
      "sdf['data'] = list(data)\n",
      "sdf['shift'] = list(plug_pos)\n",
      "sdf['orig_data'] = list(orig_data)\n",
      "sdf['good'][bad_idx == True] = False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sdf.to_pickle(\"/Users/Alex/Code/blurd/data.pandas\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pymouse\n",
      "pymouse.email_me(\"Blood analysis all done\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}